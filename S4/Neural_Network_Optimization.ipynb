{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0m2JWFliFfKT"
   },
   "source": [
    "### The objective of this exercise is to take a CNN and optimize it to attain an accuracy of 99.4% on MNIST dataset with less than 20K model parameters in less than 20 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h_Cx9q2QFgM7"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)    # Input - 28 | Output - 28 | RF -  3         RF - Receptive Field\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)   # Input - 28 | Output - 28 | RF -  5\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)                # Input - 28 | Output - 14 | RF - 10\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)  # Input - 14 | Output - 14 | RF - 12\n",
    "        self.conv4 = nn.Conv2d(128, 256, 3, padding=1) # Input - 14 | Output - 14 | RF - 14\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)                # Input -  7 | Output -  7 | RF - 28\n",
    "        self.conv5 = nn.Conv2d(256, 512, 3)            # Input -  7 | Output -  5 | RF - 30\n",
    "        self.conv6 = nn.Conv2d(512, 1024, 3)           # Input -  5 | Output -  3 | RF - 32\n",
    "        self.conv7 = nn.Conv2d(1024, 10, 3)            # Input -  3 | Output -  1 | RF - 34\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv2(F.relu(self.conv1(x)))))\n",
    "        x = self.pool2(F.relu(self.conv4(F.relu(self.conv3(x)))))\n",
    "        x = F.relu(self.conv6(F.relu(self.conv5(x))))\n",
    "        x = F.relu(self.conv7(x))\n",
    "        x = x.view(-1, 10)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xdydjYTZFyi3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 28, 28]             320\n",
      "            Conv2d-2           [-1, 64, 28, 28]          18,496\n",
      "         MaxPool2d-3           [-1, 64, 14, 14]               0\n",
      "            Conv2d-4          [-1, 128, 14, 14]          73,856\n",
      "            Conv2d-5          [-1, 256, 14, 14]         295,168\n",
      "         MaxPool2d-6            [-1, 256, 7, 7]               0\n",
      "            Conv2d-7            [-1, 512, 5, 5]       1,180,160\n",
      "            Conv2d-8           [-1, 1024, 3, 3]       4,719,616\n",
      "            Conv2d-9             [-1, 10, 1, 1]          92,170\n",
      "================================================================\n",
      "Total params: 6,379,786\n",
      "Trainable params: 6,379,786\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 1.51\n",
      "Params size (MB): 24.34\n",
      "Estimated Total Size (MB): 25.85\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "model = Net().to(device)\n",
    "summary(model, input_size=(1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DqTWLaM5GHgH"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "batch_size = 32\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                    transform=transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "                    ])),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "                    ])),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8fDefDhaFlwH"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    pbar = tqdm(train_loader)\n",
    "    for batch_idx, (data, target) in enumerate(pbar):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        pbar.set_description(desc= f'loss={loss.item()} batch_id={batch_idx}')\n",
    "\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MMWbLWO6FuHb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1875 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "loss=1.6370038986206055 batch_id=1874: 100%|██████████| 1875/1875 [00:16<00:00, 112.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.6850, Accuracy: 3895/10000 (38.95%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "for epoch in range(1, 2):\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    test(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above model performs poor on the MNIST dataset, further optimization is required!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimized Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "So5uk4EkHW6R"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 16, 3) # Input - 28 | Output - 26  | RF - 3\n",
    "        self.norm1 = nn.BatchNorm2d(16)\n",
    "        self.dropout1 = nn.Dropout(0.1)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(16, 16, 3) # Input - 26 | Output - 24 | RF - 5\n",
    "        self.norm2 = nn.BatchNorm2d(16)\n",
    "        self.dropout2 = nn.Dropout(0.1)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(16, 16, 3) # Input - 24 | Output - 22 | RF - 7\n",
    "        self.norm3 = nn.BatchNorm2d(16)\n",
    "        self.dropout3 = nn.Dropout(0.1)\n",
    "        \n",
    "        self.pool1 = nn.MaxPool2d(2, 2) # Input - 22 | Output - 11  | RF - 14\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(16, 16, 3) # Input - 11 | Output - 9  | RF - 16\n",
    "        self.norm4 = nn.BatchNorm2d(16)\n",
    "        self.dropout4 = nn.Dropout(0.1)\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(16, 16, 3)  # Input - 9 | Output - 7  | RF - 18\n",
    "        self.norm5 = nn.BatchNorm2d(16)\n",
    "        self.dropout5 = nn.Dropout(0.1)\n",
    "        \n",
    "        self.conv6 = nn.Conv2d(16, 16, 3)  # Input - 7 | Output - 5  | RF - 20\n",
    "        self.norm6 = nn.BatchNorm2d(16)\n",
    "        self.dropout6 = nn.Dropout(0.1)\n",
    "        \n",
    "        self.conv7 = nn.Conv2d(16, 10, 3) # Input - 5 | Output - 3 | RF - 22\n",
    "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.dropout1(self.norm1(F.relu(self.conv1(x))))\n",
    "        x = self.dropout2(self.norm2(F.relu(self.conv2(x))))\n",
    "        x = self.dropout3(self.norm3(F.relu(self.conv3(x))))\n",
    "        x = self.pool1(x)\n",
    "        x = self.dropout4(self.norm4(F.relu(self.conv4(x))))\n",
    "        x = self.dropout5(self.norm5(F.relu(self.conv5(x))))\n",
    "        x = self.dropout6(self.norm6(F.relu(self.conv6(x))))\n",
    "        x = self.conv7(x)\n",
    "        x = self.gap(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return F.log_softmax(x)\n",
    "#F.relu(self.conv3(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above model **Relu** before the last layer is removed and **Global Average Pooling** is added after that. The model is designed in such a way that the First Block i.e. the block which extracts Edges and Gradients, to have a Receptive Field of 7. The channel size of 16 is used across the convolutions as the MNIST dataset is not a complex dataset and has less features to learn.\n",
    "\n",
    "#### Batch Normalization\n",
    "Added Batch Normalization after every convolution layer to Normalize the channel values with mean and standard deviation of the executed batch, this helps the channels to retain useful information without exploding or vanishing the channel values due to back to back matrix multiplication in the form of Convolutions\n",
    "\n",
    "#### Dropout\n",
    "Added Dropout to the model which randomly makes a porion of channel values to 0 and helps the Network to not model noise. This is also called as Regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 26, 26]             160\n",
      "       BatchNorm2d-2           [-1, 16, 26, 26]              32\n",
      "           Dropout-3           [-1, 16, 26, 26]               0\n",
      "            Conv2d-4           [-1, 16, 24, 24]           2,320\n",
      "       BatchNorm2d-5           [-1, 16, 24, 24]              32\n",
      "           Dropout-6           [-1, 16, 24, 24]               0\n",
      "            Conv2d-7           [-1, 16, 22, 22]           2,320\n",
      "       BatchNorm2d-8           [-1, 16, 22, 22]              32\n",
      "           Dropout-9           [-1, 16, 22, 22]               0\n",
      "        MaxPool2d-10           [-1, 16, 11, 11]               0\n",
      "           Conv2d-11             [-1, 16, 9, 9]           2,320\n",
      "      BatchNorm2d-12             [-1, 16, 9, 9]              32\n",
      "          Dropout-13             [-1, 16, 9, 9]               0\n",
      "           Conv2d-14             [-1, 16, 7, 7]           2,320\n",
      "      BatchNorm2d-15             [-1, 16, 7, 7]              32\n",
      "          Dropout-16             [-1, 16, 7, 7]               0\n",
      "           Conv2d-17             [-1, 16, 5, 5]           2,320\n",
      "      BatchNorm2d-18             [-1, 16, 5, 5]              32\n",
      "          Dropout-19             [-1, 16, 5, 5]               0\n",
      "           Conv2d-20             [-1, 10, 3, 3]           1,450\n",
      "AdaptiveAvgPool2d-21             [-1, 10, 1, 1]               0\n",
      "================================================================\n",
      "Total params: 13,402\n",
      "Trainable params: 13,402\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.71\n",
      "Params size (MB): 0.05\n",
      "Estimated Total Size (MB): 0.76\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:45: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "model = Net().to(device)\n",
    "summary(model, input_size=(1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:45: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "loss=0.003216654062271118 batch_id=1874: 100%|██████████| 1875/1875 [00:10<00:00, 179.98it/s] \n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0492, Accuracy: 9844/10000 (98.44%)\n",
      "\n",
      "epoch:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.0478646457195282 batch_id=1874: 100%|██████████| 1875/1875 [00:10<00:00, 182.57it/s]    \n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0307, Accuracy: 9900/10000 (99.00%)\n",
      "\n",
      "epoch:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.20527556538581848 batch_id=1874: 100%|██████████| 1875/1875 [00:10<00:00, 179.23it/s]   \n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0317, Accuracy: 9894/10000 (98.94%)\n",
      "\n",
      "epoch:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.06568107008934021 batch_id=1874: 100%|██████████| 1875/1875 [00:10<00:00, 179.39it/s]   \n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0298, Accuracy: 9894/10000 (98.94%)\n",
      "\n",
      "epoch:  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.0016793310642242432 batch_id=1874: 100%|██████████| 1875/1875 [00:10<00:00, 183.05it/s] \n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0277, Accuracy: 9911/10000 (99.11%)\n",
      "\n",
      "epoch:  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.04335714876651764 batch_id=1874: 100%|██████████| 1875/1875 [00:10<00:00, 181.34it/s]   \n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0239, Accuracy: 9923/10000 (99.23%)\n",
      "\n",
      "epoch:  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.0014918744564056396 batch_id=1874: 100%|██████████| 1875/1875 [00:10<00:00, 181.43it/s] \n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0219, Accuracy: 9927/10000 (99.27%)\n",
      "\n",
      "epoch:  8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.02674165368080139 batch_id=1874: 100%|██████████| 1875/1875 [00:10<00:00, 181.06it/s]   \n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0219, Accuracy: 9923/10000 (99.23%)\n",
      "\n",
      "epoch:  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.007756590843200684 batch_id=1874: 100%|██████████| 1875/1875 [00:10<00:00, 176.88it/s]  \n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0205, Accuracy: 9936/10000 (99.36%)\n",
      "\n",
      "epoch:  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.0008476972579956055 batch_id=1874: 100%|██████████| 1875/1875 [00:10<00:00, 183.70it/s] \n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 9921/10000 (99.21%)\n",
      "\n",
      "epoch:  11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.001577138900756836 batch_id=1874: 100%|██████████| 1875/1875 [00:10<00:00, 179.27it/s]  \n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0207, Accuracy: 9930/10000 (99.30%)\n",
      "\n",
      "epoch:  12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.04381342977285385 batch_id=1874: 100%|██████████| 1875/1875 [00:10<00:00, 181.94it/s]   \n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0186, Accuracy: 9938/10000 (99.38%)\n",
      "\n",
      "epoch:  13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.0037747621536254883 batch_id=1874: 100%|██████████| 1875/1875 [00:10<00:00, 181.20it/s] \n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0185, Accuracy: 9946/10000 (99.46%)\n",
      "\n",
      "epoch:  14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.0012367665767669678 batch_id=1874: 100%|██████████| 1875/1875 [00:10<00:00, 181.53it/s] \n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0193, Accuracy: 9929/10000 (99.29%)\n",
      "\n",
      "epoch:  15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.010296612977981567 batch_id=1874: 100%|██████████| 1875/1875 [00:10<00:00, 179.42it/s]  \n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0188, Accuracy: 9933/10000 (99.33%)\n",
      "\n",
      "epoch:  16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.0017636120319366455 batch_id=1874: 100%|██████████| 1875/1875 [00:10<00:00, 181.93it/s] \n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0213, Accuracy: 9937/10000 (99.37%)\n",
      "\n",
      "epoch:  17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.0008503347635269165 batch_id=1874: 100%|██████████| 1875/1875 [00:10<00:00, 180.62it/s] \n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 9937/10000 (99.37%)\n",
      "\n",
      "epoch:  18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.03054824471473694 batch_id=1874: 100%|██████████| 1875/1875 [00:10<00:00, 181.62it/s]   \n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0212, Accuracy: 9934/10000 (99.34%)\n",
      "\n",
      "epoch:  19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.0003806948661804199 batch_id=1874: 100%|██████████| 1875/1875 [00:10<00:00, 180.91it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0172, Accuracy: 9947/10000 (99.47%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "for epoch in range(1, 20):\n",
    "    print(\"epoch: \", epoch)\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    test(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the careful changes done iteratively to the network, an accuracy of **99.47%** has been attained in less than **20** epochs with just **~13K** model parameters!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "EVA4 - Session 2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
